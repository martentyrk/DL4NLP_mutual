# -*- coding: utf-8 -*-
"""BERT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oMeAdmecvCuV9Tup-rR2V_T2bEaaSxbj
"""
import os
from pytorch_lightning.loggers import CometLogger
import numpy as np
import torch
import torch.nn.functional as F
import torch.nn as nn
from datetime import datetime
from torch.utils.data import DataLoader
from dotenv import load_dotenv
import torch.optim as optim
import torch.utils.data as data
from torch.utils.data import DataLoader, Dataset
from transformers import AutoTokenizer
from transformers import BertConfig, BertForMultipleChoice
from dataset import load_and_cache_examples, processors
import pytorch_lightning as pl
from torchmetrics.retrieval import RetrievalRecall, RetrievalMRR
from torchmetrics.classification import MulticlassRecall
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint
from pytorch_lightning.loggers import WandbLogger

os.environ["TOKENIZERS_PARALLELISM"] = "false"
load_dotenv()


def simple_accuracy(preds, labels):
    return (preds == labels).mean()


def compute_mrr(logits, labels, mrr, device):
    row = logits.shape[0]
    col = logits.shape[1]
    indexes = torch.arange(row).unsqueeze(1).expand(row, col).contiguous().view(-1).to(device)
    preds_MRR = logits.contiguous().view(-1)
    targets = torch.rand((row,col))>1
    for i, j in enumerate(labels):
        targets[i, j] = True
    targets = targets.view(-1).to(device)
    mrr_score = mrr(preds_MRR, targets, indexes=indexes)
    return mrr_score


def load_model(model_name, num_classes, freeze_lm=True):
    """
    This function loads the a pretrained model and add a classifier layer on top
    Inputs:
        model_name - name of the pretrained model
        in_features: input dimension of classifier layer
        num_classes: number of classes which is the dimension of output of classifier layer
        freeze_lm: boolean parameter indicating if to freeze weights of pretrained model
    """
    ## Load pretrained model
    if model_name.lower() == 'bert':
        model_config = BertConfig.from_pretrained("bert-base-uncased", num_labels=num_classes)
        model = BertForMultipleChoice.from_pretrained("bert-base-uncased", config=model_config)
    elif model_name.lower() == 'tod_bert':
        model_config = BertConfig.from_pretrained('TODBERT/TOD-BERT-JNT-V1', num_labels=num_classes)
        model = BertForMultipleChoice.from_pretrained('TODBERT/TOD-BERT-JNT-V1', config=model_config)
    ## freeze all weights in LM to reduce computational complex
    if freeze_lm:
        for name, param in model.named_parameters():
            if name.startswith('classifier'):
                param.requires_grad = False

    ## Define a classifier layer and add it to the LM

    return model


class Mutual_Module(pl.LightningModule):
    """
    Torch lightning training pipeline
    """

    def __init__(self, args):
        """
          Inputs:
              args - user defined arguments
        """
        super().__init__()
        self.save_hyperparameters()
        processor = processors[args.task_name]()
        label_list = processor.get_labels(args)
        num_labels = len(label_list)
        self.model = load_model(args.model_name,
                                num_labels,
                                args.freeze_lm)
        self.loss_module = nn.CrossEntropyLoss()
        self.args = args
        
        self.r1 = MulticlassRecall(top_k=1, average='micro', num_classes=num_labels)
        self.r2 = MulticlassRecall(top_k=2, average='micro', num_classes=num_labels)
        
        self.r1_test = MulticlassRecall(top_k=1, average='micro', num_classes=4)
        self.r2_test = MulticlassRecall(top_k=2, average='micro', num_classes=4)
        self.mrr = RetrievalMRR()

    def forward(self, instance):
        return self.model(torch.Tensor(instance))

    # TODO: Add hparameter for learning rate
    def configure_optimizers(self):
        optimizer = optim.AdamW(self.parameters(), 1e-5)

        if self.args.lr_scheduler:
            print('TRAINING WITH LEARNING RATE SCHEDULER')
            scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10, 25], gamma=0.1)
            return [optimizer], [scheduler]

        print('TRAINING WITHOUT LEARNING RATE SCHEDULER')
        return optimizer

    def soft_maximum(self, logits, temperature=0.1):
        # Replace -inf with a large negative number
        logits = torch.where(logits == float('-inf'), torch.tensor(-1e10).to(logits.device), logits)
        probs = torch.nn.functional.softmax(logits / temperature, dim=-1)
        soft_max = torch.sum(probs * logits, dim=-1)
        return soft_max

    def contrastive_loss(self, outputs, labels):
        logits = outputs.logits

        # Logits for the correct answers
        positive_logits = logits[torch.arange(logits.size(0)), labels]

        # Set the logits for the correct answers to negative infinity, so they are ignored when finding the maximum
        negative_logits = logits.clone()
        negative_logits[torch.arange(logits.size(0)), labels] = float('-inf')

        # Find the maximum value in each row, which corresponds to the logit of the closest incorrect answer
        max_negative_logits = self.soft_maximum(negative_logits, temperature=0.1)

        # Calculate loss
        loss = F.leaky_relu(max_negative_logits - positive_logits + self.args.contrastive_margin)

        return loss.mean()

    def correlation_loss(self, outputs):
        # Extract the logits for each option
        logits = outputs.logits

        losses = []
        device = logits.device
        # Calculate the correlation matrix for each sample separately
        for i in range(logits.shape[0]):
            sample = logits[i]  # Get the i-th sample
            mean_sample = torch.mean(sample)
            std_deviation_sample = torch.std(sample)
            cov_matrix_sample = torch.matmul((sample - mean_sample).unsqueeze(1), (sample - mean_sample).unsqueeze(0))
            correlation_matrix_sample = cov_matrix_sample / (std_deviation_sample ** 2)
            num_options = correlation_matrix_sample.size(0)
            off_diagonal = correlation_matrix_sample - torch.eye(num_options, device=device)
            losses.append(off_diagonal.pow(2).sum())

        loss = sum(losses) / len(losses)
        return loss

    def training_step(self, batch):
        input_ids, attention_masks, token_type_ids, labels = self.unpack_batch(batch)

        outputs = self.model(input_ids=input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids,
                             labels=labels)
        loss, logits = outputs[:2]

        preds = logits.detach().cpu().numpy()
        preds_pos_1 = np.argmax(preds, axis=1)
        out_label_ids = labels.detach().cpu().numpy()
        acc = simple_accuracy(preds_pos_1, out_label_ids)

        loss = self.args.crossentropy_weight * self.loss_module(logits, labels)

        if self.args.use_contrastive or self.args.use_correlation:
            if self.args.use_contrastive and self.args.use_correlation:
                # print('USING BOTH')
                loss += self.args.contrastive_weight * self.contrastive_loss(outputs,
                                                                        labels) + self.args.correlation_weight * self.correlation_loss(
                    outputs)
            elif self.args.use_contrastive:
                # print('USING CONTRASTIVE')
                loss += self.args.contrastive_weight * self.contrastive_loss(outputs, labels)
            else:
                # print('USING CORRELATION')
                loss += self.args.correlation_weight * self.correlation_loss(outputs)

        # Compute recall@1 and recall@2
        recall1 = self.r1(logits, labels)
        recall2 = self.r2(logits, labels)

        # Compute mrr score
        mrr_score = compute_mrr(logits, labels, self.mrr, self.args.device)
        #
        self.log('train_acc', acc, on_step=False, on_epoch=True)
        self.log('train_loss', loss)
        self.log('train_R@1', recall1)
        self.log('train_R@2', recall2)
        self.log('train_MRR', mrr_score)
        return loss

    def validation_step(self, batch, verbose):
        input_ids, attention_masks, token_type_ids, labels = self.unpack_batch(batch)

        outputs = self.model(input_ids=input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids,
                             labels=labels)
        _, logits = outputs[:2]

        if self.args.A_plus:
            logits = logits[:, :-1]

        preds = logits.detach().cpu().numpy()
        preds_pos_1 = np.argmax(preds, axis=1)
        out_label_ids = labels.detach().cpu().numpy()
        acc = simple_accuracy(preds_pos_1, out_label_ids)
        
        #Compute recall@1 and recall@2
        recall1 = self.r1_test(logits, labels)
        recall2 = self.r2_test(logits, labels)

        #Compute MRR score
        mrr_score = compute_mrr(logits, labels, self.mrr, self.args.device)
        #
        self.log('val_acc', acc)
        self.log('val_R@1', recall1)
        self.log('val_R@2', recall2)
        self.log('val_MRR', mrr_score)

    def test_step(self, batch, verbose):
        input_ids, attention_masks, token_type_ids, labels = self.unpack_batch(batch)

        outputs = self.model(input_ids=input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids,
                             labels=labels)
        _, logits = outputs[:2]

        if self.args.A_plus:
            logits = logits[:, :-1]
        
        preds = logits.detach().cpu().numpy()
        preds_pos_1 = np.argmax(preds, axis=1)
        out_label_ids = labels.detach().cpu().numpy()
        acc = simple_accuracy(preds_pos_1, out_label_ids)
        
        #Compute recall@1 and recall@2
        recall1 = self.r1_test(logits, labels)
        recall2 = self.r2_test(logits, labels)

        #Compute MRR score
        mrr_score = compute_mrr(logits, labels, self.mrr, self.args.device)
        #
        self.log('test_acc', acc)
        self.log('test_R@1', recall1)
        self.log('test_R@2', recall2)
        self.log('test_MRR', mrr_score)

    def unpack_batch(self, batch):
        input_ids = batch[0]
        attention_masks = batch[1]
        token_type_ids = batch[2]
        labels = batch[3]
        return input_ids, attention_masks, token_type_ids, labels


def fine_tune(args):
    """
    Function to conduct fine tuning
    Inputs:
        args - user defined arguments
    """
    # Create dataset
    if args.model_name.lower() == 'bert':
        tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
    elif args.model_name.lower() == 'tod_bert':
        tokenizer = AutoTokenizer.from_pretrained("TODBERT/TOD-BERT-JNT-V1")
    else:
        print("please check model name!")
    
    train_dataset, val_dataset = load_and_cache_examples(args, tokenizer)
    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, num_workers=args.num_workers)    
    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, num_workers=args.num_workers)
    
    test_dataset, _ = load_and_cache_examples(args, tokenizer, evaluate=True)
    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, num_workers=args.num_workers)

    # Create a PyTorch Lightning trainer with the generation callback
    current_dateTime = datetime.now()
    timestamp = str(str(current_dateTime.hour) + '_' + str(current_dateTime.minute) + '_d' + str(current_dateTime.day) +'/' + str(current_dateTime.month))
    
    experiment_name = str(args.model_name + "_batch_size" + str(args.batch_size) + '_epochs'+str(args.max_epochs) + 'time_' + timestamp)
    # Create a PyTorch Lightning trainer with the generation callback
    
    # wandb_logger = WandbLogger(
    #     log_model="all",
    #     name=experiment_name,
    #     save_dir=args.checkpoint_path,
    #     project='bert')    
    comet_logger = CometLogger(
        api_key=os.getenv('COMET_API_KEY'),  ## change to your api key
        project_name="mutual",
        workspace=os.getenv('WORKSPACE'),
        save_dir="checkpoint/", 
        experiment_name=experiment_name
    )
    trainer = pl.Trainer(default_root_dir=os.path.join(args.checkpoint_path, args.model_name),
                         accelerator=args.device,
                         devices=1,
                         max_epochs=args.max_epochs,
                         callbacks=[ModelCheckpoint(save_weights_only=True, mode="max", monitor="val_acc", dirpath=experiment_name),
                                    LearningRateMonitor("epoch")],
                         enable_progress_bar=True,
                         logger=comet_logger)
    trainer.logger._log_graph = True  # If True, we plot the computation graph in tensorboard

    # Check whether pretrained model exists. If yes, load it and skip training
    pretrained_filename = os.path.join(args.checkpoint_path, args.model_name + ".ckpt")

    print(pretrained_filename, ' pretrained filename!!!!!!')

    if os.path.isfile(pretrained_filename):
        print(f"Found pretrained model at {pretrained_filename}, loading...")
        model = Mutual_Module.load_from_checkpoint(
            pretrained_filename)  # Automatically loads the model with the saved hyperparameters
    else:
        pl.seed_everything(args.seed)  # To be reproducable
        model = Mutual_Module(args)
        trainer.fit(model, train_loader, val_loader)
        model = Mutual_Module.load_from_checkpoint(
            trainer.checkpoint_callback.best_model_path)  # Load best checkpoint after training

    # Test best model on validation and test set
    val_result = trainer.test(model, val_loader, verbose=False)
    test_result = trainer.test(model, test_loader, verbose=False)
    result = {"test": test_result, "val": val_result}

    return model, result